{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**COURSE: PRDL/MLLB**\n",
        "\n",
        "**PROJECT: Deep Learning**\n",
        "\n",
        "**TEACHER: Luis Hernández Gómez**\n",
        "\n",
        "**AUTHORS: MARONE Mamadou / RACHIDI Inass**\n",
        "\n",
        "**NOTEBOOK: CNN & LSTM**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SETUP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## INSTALLING MODULES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zuPpR2GG9fX"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install tensorflow\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## IMPORTING LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBvSEAKRwjIj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Conv1D, MaxPooling1D\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w23hMVTwHNTj",
        "outputId": "5785beb3-40ee-46ba-b73f-25f561cc2b94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyYL7jUbxYsX"
      },
      "source": [
        "# Load and Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# os.chdir(r\"C:\\Users\\maron\\OneDrive\\02-Documents\\00.ETUDES\\00.ECOLE_D_INGE\\00.CYCLE_ING_FORMATION_INIT\\00.3EME_ANNEE_INIT\\00.A_COURS\\00.PRDL\\06.PROJECTS\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "Nw7PYkAevymd",
        "outputId": "de42df4a-85d5-4733-a8c1-cd5bfb14d715"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>title</th>\n",
              "      <th>body</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ARTS &amp; CULTURE</td>\n",
              "      <td>model agenc enabl sexual predat year former ag...</td>\n",
              "      <td>octob carolyn kramer receiv disturb phone call...</td>\n",
              "      <td>model agenc enabl sexual predat year former ag...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ARTS &amp; CULTURE</td>\n",
              "      <td>actor jeff hiller talk bright color bold patte...</td>\n",
              "      <td>week talk actor jeff hiller hit broadway play ...</td>\n",
              "      <td>actor jeff hiller talk bright color bold patte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ARTS &amp; CULTURE</td>\n",
              "      <td>new yorker cover put trump hole racist comment</td>\n",
              "      <td>new yorker take presid donald trump ask u woul...</td>\n",
              "      <td>new yorker cover put trump hole racist comment...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         category                                              title  \\\n",
              "0  ARTS & CULTURE  model agenc enabl sexual predat year former ag...   \n",
              "1  ARTS & CULTURE  actor jeff hiller talk bright color bold patte...   \n",
              "2  ARTS & CULTURE     new yorker cover put trump hole racist comment   \n",
              "\n",
              "                                                body  \\\n",
              "0  octob carolyn kramer receiv disturb phone call...   \n",
              "1  week talk actor jeff hiller hit broadway play ...   \n",
              "2  new yorker take presid donald trump ask u woul...   \n",
              "\n",
              "                                                text  \n",
              "0  model agenc enabl sexual predat year former ag...  \n",
              "1  actor jeff hiller talk bright color bold patte...  \n",
              "2  new yorker cover put trump hole racist comment...  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_cleaned = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/PROJET_DL_MLLB/DATA/CLEANED/corpus_cleaned.csv\")\n",
        "df_cleaned.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1t8hPx8Lxc9x"
      },
      "outputs": [],
      "source": [
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "df_cleaned['encoded_labels'] = label_encoder.fit_transform(df_cleaned['category'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the data into features and labels\n",
        "X = df_cleaned['text']\n",
        "y = df_cleaned['encoded_labels']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdzKnqv5CzIi"
      },
      "source": [
        "# Tokenize and Pad Text Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jm59AWUC0-p"
      },
      "outputs": [],
      "source": [
        "# Tokenize the text\n",
        "max_words = 10000\n",
        "tokenizer = Tokenizer(num_words = max_words, oov_token = '<OOV>')\n",
        "tokenizer.fit_on_texts(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert text to sequences\n",
        "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_sequences = tokenizer.texts_to_sequences(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pad sequences for equal length\n",
        "max_length = 500\n",
        "X_train_padded = pad_sequences(X_train_sequences, maxlen = max_length, padding = 'post', truncating = 'post')\n",
        "X_test_padded = pad_sequences(X_test_sequences, maxlen = max_length, padding = 'post', truncating = 'post')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzzipXmUC4BH"
      },
      "source": [
        "# MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkxUZ_E-G9fg",
        "outputId": "742a1539-9b72-4c11-a484-0ba62903fca7"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "embedding_dim = 128\n",
        "# Embedding layer\n",
        "model.add(Embedding(input_dim = max_words, output_dim = embedding_dim, input_length = max_length))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_filters = 256\n",
        "filter_size = 3\n",
        "\n",
        "# CNN layer\n",
        "model.add(Conv1D(filters = num_filters, kernel_size = filter_size, activation = 'relu'))\n",
        "model.add(MaxPooling1D(pool_size = 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# LSTM layer\n",
        "model.add(LSTM(256, activation = 'tanh', recurrent_activation = 'sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Output layer\n",
        "num_classes = len(label_encoder.classes_)\n",
        "model.add(Dense(num_classes, activation = 'softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer = 'Adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g74PI_hfDAwd"
      },
      "source": [
        "# TRAINING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zibdRdKCDFEY"
      },
      "outputs": [],
      "source": [
        "epochs = 40\n",
        "batch_size = 10\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# One-hot encode the labels\n",
        "y_train_one_hot = to_categorical(y_train, num_classes = num_classes)\n",
        "y_test_one_hot = to_categorical(y_test, num_classes = num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8h6y4xQG9fh"
      },
      "source": [
        "W notice that the batch size affect a lot the accuracy :\n",
        "    - 0.45 of accuracy with 100\n",
        "    - 0.50 of accuracy with 50\n",
        "    - 0.58 of accuracy with 30\n",
        "Number of epoch:\n",
        "    - with batch size of 30 - epoch of 30 : 62%\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJiOWWVIc2KC"
      },
      "outputs": [],
      "source": [
        "# Fit the model with one-hot encoded labels\n",
        "history = model.fit(X_train_padded, y_train_one_hot, epochs = epochs, batch_size = batch_size, validation_data = (X_test_padded, y_test_one_hot))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPcSY3h5RLoD"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training and validation loss values\n",
        "plt.plot(history.history['loss'], label = 'Training Loss')\n",
        "plt.plot(history.history['val_loss'], label = 'Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpJr6uHzG9fi"
      },
      "source": [
        "Notice:\n",
        "- with the **default activation** functions:\n",
        "    - The model underfits(0.17 accuracy) when we use **Adam** as optimizer algorithm. When We have changed it to **RMSprop**, we got 0.23 of accuracy and the underfitting decreases.\n",
        "- with the activation functions **activation='tanh'** and **recurrent_activation='sigmoid'** :\n",
        "    - the Adam perform better than the RMSprop (17% Vs 22%)\n",
        "    - We have also tried the optimizer **Nadam**(17%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxcW-U2aDKvS"
      },
      "source": [
        "## EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "zSLLLAPhDME0",
        "outputId": "049f65e5-b072-4392-989d-e29571a0a406"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  1/172 [..............................] - ETA: 18s - loss: 0.0349 - accuracy: 1.0000"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "172/172 [==============================] - 14s 83ms/step - loss: 0.0152 - accuracy: 0.9960\n",
            "Test Loss: 0.015177085064351559\n",
            "Test Accuracy: 0.9960007071495056\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(X_test_padded, y_test_one_hot)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the model on the test set\n",
        "y_pred = model.predict_classes(X_test_padded)\n",
        "\n",
        "# Calculate additional metrics\n",
        "accuracy = accuracy_score(y_test_one_hot, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test_one_hot, y_pred)\n",
        "classification_rep = classification_report(y_test_one_hot, y_pred)\n",
        "\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "\n",
        "# Extract precision, recall, and F1 score\n",
        "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test_one_hot, y_pred, average='weighted')\n",
        "\n",
        "print(\"Weighted Precision:\", precision)\n",
        "print(\"Weighted Recall:\", recall)\n",
        "print(\"Weighted F1 Score:\", f1_score)\n",
        "\n",
        "# Visualize the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
